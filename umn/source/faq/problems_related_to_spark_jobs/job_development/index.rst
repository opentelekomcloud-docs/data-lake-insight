:original_name: dli_03_0217.html

.. _dli_03_0217:

Job Development
===============

-  :ref:`How Do I Use Spark to Write Data into a DLI Table? <dli_03_0107>`
-  :ref:`How Do I Set the AK/SK for a Queue to Operate an OBS Table? <dli_03_0017>`
-  :ref:`How Do I View the Resource Usage of DLI Spark Jobs? <dli_03_0102>`
-  :ref:`How Do I Use Python Scripts to Access the MySQL Database If the pymysql Module Is Missing from the Spark Job Results Stored in MySQL? <dli_03_0076>`
-  :ref:`How Do I Run a Complex PySpark Program in DLI? <dli_03_0082>`
-  :ref:`How Does a Spark Job Access a MySQL Database? <dli_03_0127>`
-  :ref:`How Do I Use JDBC to Set the spark.sql.shuffle.partitions Parameter to Improve the Task Concurrency? <dli_03_0068>`
-  :ref:`How Do I Read Uploaded Files for a Spark Jar Job? <dli_03_0118>`

.. toctree::
   :maxdepth: 1
   :hidden: 

   how_do_i_use_spark_to_write_data_into_a_dli_table
   how_do_i_set_the_ak_sk_for_a_queue_to_operate_an_obs_table
   how_do_i_view_the_resource_usage_of_dli_spark_jobs
   how_do_i_use_python_scripts_to_access_the_mysql_database_if_the_pymysql_module_is_missing_from_the_spark_job_results_stored_in_mysql
   how_do_i_run_a_complex_pyspark_program_in_dli
   how_does_a_spark_job_access_a_mysql_database
   how_do_i_use_jdbc_to_set_the_spark.sql.shuffle.partitions_parameter_to_improve_the_task_concurrency
   how_do_i_read_uploaded_files_for_a_spark_jar_job
