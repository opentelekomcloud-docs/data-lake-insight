:original_name: dli_03_0021.html

.. _dli_03_0021:

Problems Related to Spark Jobs
==============================

-  :ref:`Spark Jobs <dli_03_0201>`
-  :ref:`How Do I Use Spark to Write Data into a DLI Table? <dli_03_0107>`
-  :ref:`How Do I Set the AK/SK for a Queue to Operate an OBS Table? <dli_03_0017>`
-  :ref:`How Do I View the Resource Usage of DLI Spark Jobs? <dli_03_0102>`
-  :ref:`How Do I Use Python Scripts to Access the MySQL Database If the pymysql Module Is Missing from the Spark Job Results Stored in MySQL? <dli_03_0076>`
-  :ref:`How Do I Run a Complex PySpark Program in DLI? <dli_03_0082>`
-  :ref:`How Does a Spark Job Access a MySQL Database? <dli_03_0127>`
-  :ref:`How Do I Use JDBC to Set the spark.sql.shuffle.partitions Parameter to Improve the Task Concurrency? <dli_03_0068>`
-  :ref:`How Do I Read Uploaded Files for a Spark Jar Job? <dli_03_0118>`
-  :ref:`Why Are Errors "ResponseCode: 403" and "ResponseStatus: Forbidden" Reported When a Spark Job Accesses OBS Data? <dli_03_0156>`
-  :ref:`Why Is Error "verifyBucketExists on XXXX: status [403]" Reported When I Use a Spark Job to Access an OBS Bucket That I Have Access Permission? <dli_03_0164>`
-  :ref:`Why Is a Job Running Timeout Reported When a Spark Job Runs a Large Amount of Data? <dli_03_0157>`
-  :ref:`Why Does the Job Fail to Be Executed and the Log Shows that the File Directory Is Abnormal When I Use a Spark Job to Access Files in SFTP? <dli_03_0188>`
-  :ref:`Why Does the Job Fail to Be Executed Due to Insufficient Database and Table Permissions? <dli_03_0192>`
-  :ref:`Why Can't I Find the Specified Python Environment After Adding the Python Package? <dli_03_0077>`
-  :ref:`Why Is a Spark Jar Job Stuck in the Submitting State? <dli_03_0220>`

.. toctree::
   :maxdepth: 1
   :hidden: 

   spark_jobs
   how_do_i_use_spark_to_write_data_into_a_dli_table
   how_do_i_set_the_ak_sk_for_a_queue_to_operate_an_obs_table
   how_do_i_view_the_resource_usage_of_dli_spark_jobs
   how_do_i_use_python_scripts_to_access_the_mysql_database_if_the_pymysql_module_is_missing_from_the_spark_job_results_stored_in_mysql
   how_do_i_run_a_complex_pyspark_program_in_dli
   how_does_a_spark_job_access_a_mysql_database
   how_do_i_use_jdbc_to_set_the_spark.sql.shuffle.partitions_parameter_to_improve_the_task_concurrency
   how_do_i_read_uploaded_files_for_a_spark_jar_job
   why_are_errors_responsecode_403_and_responsestatus_forbidden_reported_when_a_spark_job_accesses_obs_data
   why_is_error_verifybucketexists_on_xxxx_status_[403]_reported_when_i_use_a_spark_job_to_access_an_obs_bucket_that_i_have_access_permission
   why_is_a_job_running_timeout_reported_when_a_spark_job_runs_a_large_amount_of_data
   why_does_the_job_fail_to_be_executed_and_the_log_shows_that_the_file_directory_is_abnormal_when_i_use_a_spark_job_to_access_files_in_sftp
   why_does_the_job_fail_to_be_executed_due_to_insufficient_database_and_table_permissions
   why_cant_i_find_the_specified_python_environment_after_adding_the_python_package
   why_is_a_spark_jar_job_stuck_in_the_submitting_state
